{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adienlopez/EAN13-Barcode-Generator/blob/main/Webuy_Complete_DVD_Listing_Scraper_V1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1bSajkvhnMi",
        "outputId": "e47133c6-bc28-47b6-923a-bdf134886035"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m499.2/499.2 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\n",
            "ğŸ”„ Found checkpoint:\n",
            "   Year: 2015\n",
            "   Rating: 12\n",
            "   Last completed page: 21\n",
            "   Items scraped: 6292\n",
            "   Timestamp: 2025-07-23 13:18:10\n",
            "\n",
            "Press Enter to resume from here, or type 'new' for fresh start: \n",
            "ğŸ”» Enter the END year (currently resuming 2015): 2010\n",
            "ğŸ“‹ Using existing 'DVD' worksheet (appending data)\n",
            "ğŸ”„ Successfully set resume point: Rating '12' (index 2), Page: 22\n",
            "ğŸŸ¢ Scraping DVDs for Year: 2015, Rating: 12\n",
            "   ğŸ“ Resuming from page 22\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=12&Year=2015&page=22\n",
            "  âš ï¸ Failed to load product links: Message: \n",
            "\n",
            "   ğŸ” Page 22 - Found 0 product links\n",
            "ğŸŸ¢ Scraping DVDs for Year: 2015, Rating: 15\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=15&Year=2015\n",
            "   ğŸ” Page 1 - Found 17 product links\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=15&Year=2015&page=2\n",
            "   ğŸ” Page 2 - Found 17 product links\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=15&Year=2015&page=3\n",
            "   ğŸ” Page 3 - Found 17 product links\n",
            "  âœ… Wrote 51 rows | Total scraped: 6343\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=15&Year=2015&page=4\n",
            "   ğŸ” Page 4 - Found 17 product links\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=15&Year=2015&page=5\n",
            "   ğŸ” Page 5 - Found 17 product links\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=15&Year=2015&page=6\n",
            "   ğŸ” Page 6 - Found 17 product links\n",
            "  âœ… Wrote 51 rows | Total scraped: 6394\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=15&Year=2015&page=7\n",
            "   ğŸ” Page 7 - Found 17 product links\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=15&Year=2015&page=8\n",
            "   ğŸ” Page 8 - Found 17 product links\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=15&Year=2015&page=9\n",
            "   ğŸ” Page 9 - Found 17 product links\n",
            "  âœ… Wrote 51 rows | Total scraped: 6445\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=15&Year=2015&page=10\n",
            "   ğŸ” Page 10 - Found 17 product links\n",
            "  ğŸ’¾ Checkpoint saved at Year 2015, Rating 15, Page 10\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=15&Year=2015&page=11\n",
            "   ğŸ” Page 11 - Found 17 product links\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=15&Year=2015&page=12\n",
            "   ğŸ” Page 12 - Found 17 product links\n",
            "  âœ… Wrote 51 rows | Total scraped: 6496\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=15&Year=2015&page=13\n",
            "   ğŸ” Page 13 - Found 17 product links\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=15&Year=2015&page=14\n",
            "   ğŸ” Page 14 - Found 17 product links\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=15&Year=2015&page=15\n",
            "   ğŸ” Page 15 - Found 17 product links\n",
            "  âœ… Wrote 51 rows | Total scraped: 6547\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=15&Year=2015&page=16\n",
            "   ğŸ” Page 16 - Found 17 product links\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=15&Year=2015&page=17\n",
            "   ğŸ” Page 17 - Found 17 product links\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=15&Year=2015&page=18\n",
            "   ğŸ” Page 18 - Found 17 product links\n",
            "  âœ… Wrote 51 rows | Total scraped: 6598\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=15&Year=2015&page=19\n",
            "   ğŸ” Page 19 - Found 17 product links\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=15&Year=2015&page=20\n",
            "   ğŸ” Page 20 - Found 17 product links\n",
            "  ğŸ’¾ Checkpoint saved at Year 2015, Rating 15, Page 20\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=15&Year=2015&page=21\n",
            "   ğŸ” Page 21 - Found 17 product links\n",
            "  âœ… Wrote 51 rows | Total scraped: 6649\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=15&Year=2015&page=22\n",
            "   ğŸ” Page 22 - Found 17 product links\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=15&Year=2015&page=23\n",
            "   ğŸ” Page 23 - Found 17 product links\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=15&Year=2015&page=24\n",
            "   ğŸ” Page 24 - Found 17 product links\n",
            "  âœ… Wrote 51 rows | Total scraped: 6700\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=15&Year=2015&page=25\n",
            "   ğŸ” Page 25 - Found 17 product links\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=15&Year=2015&page=26\n",
            "   ğŸ” Page 26 - Found 17 product links\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=15&Year=2015&page=27\n",
            "   ğŸ” Page 27 - Found 17 product links\n",
            "  âœ… Wrote 51 rows | Total scraped: 6751\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=15&Year=2015&page=28\n",
            "   ğŸ” Page 28 - Found 17 product links\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=15&Year=2015&page=29\n",
            "   ğŸ” Page 29 - Found 17 product links\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=15&Year=2015&page=30\n",
            "   ğŸ” Page 30 - Found 17 product links\n",
            "  âœ… Wrote 51 rows | Total scraped: 6802\n",
            "  ğŸ’¾ Checkpoint saved at Year 2015, Rating 15, Page 30\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=15&Year=2015&page=31\n",
            "   ğŸ” Page 31 - Found 17 product links\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=15&Year=2015&page=32\n",
            "   ğŸ” Page 32 - Found 17 product links\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=15&Year=2015&page=33\n",
            "   ğŸ” Page 33 - Found 17 product links\n",
            "  âœ… Wrote 51 rows | Total scraped: 6853\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=15&Year=2015&page=34\n",
            "   ğŸ” Page 34 - Found 17 product links\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=15&Year=2015&page=35\n",
            "   ğŸ” Page 35 - Found 17 product links\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=15&Year=2015&page=36\n",
            "   ğŸ” Page 36 - Found 17 product links\n",
            "  âœ… Wrote 51 rows | Total scraped: 6904\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=15&Year=2015&page=37\n",
            "   ğŸ” Page 37 - Found 17 product links\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=15&Year=2015&page=38\n",
            "   ğŸ” Page 38 - Found 17 product links\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=15&Year=2015&page=39\n",
            "   ğŸ” Page 39 - Found 17 product links\n",
            "  âœ… Wrote 51 rows | Total scraped: 6955\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=15&Year=2015&page=40\n",
            "   ğŸ” Page 40 - Found 17 product links\n",
            "  ğŸ’¾ Checkpoint saved at Year 2015, Rating 15, Page 40\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=15&Year=2015&page=41\n",
            "   ğŸ” Page 41 - Found 17 product links\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=15&Year=2015&page=42\n",
            "   ğŸ” Page 42 - Found 17 product links\n",
            "  âœ… Wrote 51 rows | Total scraped: 7006\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=15&Year=2015&page=43\n",
            "   ğŸ” Page 43 - Found 17 product links\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=15&Year=2015&page=44\n",
            "   ğŸ” Page 44 - Found 17 product links\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=15&Year=2015&page=45\n",
            "   ğŸ” Page 45 - Found 17 product links\n",
            "  âœ… Wrote 51 rows | Total scraped: 7057\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=15&Year=2015&page=46\n",
            "   ğŸ” Page 46 - Found 17 product links\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=15&Year=2015&page=47\n",
            "   ğŸ” Page 47 - Found 17 product links\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=15&Year=2015&page=48\n",
            "   ğŸ” Page 48 - Found 17 product links\n",
            "  âœ… Wrote 51 rows | Total scraped: 7108\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=15&Year=2015&page=49\n",
            "   ğŸ” Page 49 - Found 17 product links\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=15&Year=2015&page=50\n",
            "   ğŸ” Page 50 - Found 16 product links\n",
            "  ğŸ’¾ Checkpoint saved at Year 2015, Rating 15, Page 50\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=15&Year=2015&page=51\n",
            "  âš ï¸ No product links found. Dumping page source snippet for review:\n",
            "<html lang=\"en-GB\"><head><meta charset=\"utf-8\">\n",
            "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1, maximum-scale=1.0, minimum-scale=1.0, user-scalable=no\">\n",
            "<title>CeX (UK) : Stock search</title>\n",
            "<style>@font-face{font-family:Poppins;font-style:normal;font-weight:300;src:local(\"Poppins\"),url(/_nuxt/poppins-light.g4ayFKwt.woff) format(\"woff\")}@font-face{font-family:Poppins;font-style:normal;font-weight:400;src:local(\"Poppins\"),url(/_nuxt/poppins-regular.DXw2tWI_.woff) format(\"woff\")}@font-face{font-family:Poppins;font-style:normal;font-weight:500;src:local(\"Poppins\"),url(/_nuxt/poppins-medium.BiFSRsrR.woff) format(\"woff\")}@font-face{font-family:Poppins;font-style:normal;font-weight:600;src:local(\"Poppins\"),url(/_nuxt/poppins-semibold.CfvoOXnn.woff) format(\"woff\")}@font-face{font-family:Poppins;font-style:normal;font-weight:700;src:local(\"Poppins\"),url(/_nuxt/poppins-bold.BikI6_8o.woff) format(\"woff\")}</style>\n",
            "<style>html{box-sizing:border-box;-webkit-text-size-adjust:100\n",
            "   ğŸ” Page 51 - Found 0 product links\n",
            "  âœ… Wrote remaining 33 rows for Year 2015, Rating 15\n",
            "ğŸŸ¢ Scraping DVDs for Year: 2015, Rating: 18\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=18&Year=2015\n",
            "   ğŸ” Page 1 - Found 17 product links\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=18&Year=2015&page=2\n",
            "   ğŸ” Page 2 - Found 17 product links\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=18&Year=2015&page=3\n",
            "   ğŸ” Page 3 - Found 17 product links\n",
            "  âš ï¸ Attempt 1 failed on page 3: APIError: [503]: The service is currently unavailable.\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=18&Year=2015&page=3\n",
            "   ğŸ” Page 3 - Found 17 product links\n",
            "  â¹ï¸  No new products on page 3 - stopping pagination for this year/rating\n",
            "  âœ… Wrote remaining 51 rows for Year 2015, Rating 18\n",
            "ğŸŸ¢ Scraping DVDs for Year: 2015, Rating: E\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=E&Year=2015\n",
            "   ğŸ” Page 1 - Found 17 product links\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=E&Year=2015&page=2\n",
            "   ğŸ” Page 2 - Found 17 product links\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=E&Year=2015&page=3\n",
            "   ğŸ” Page 3 - Found 17 product links\n",
            "  âœ… Wrote 51 rows | Total scraped: 7243\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=E&Year=2015&page=4\n",
            "   ğŸ” Page 4 - Found 17 product links\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=E&Year=2015&page=5\n",
            "   ğŸ” Page 5 - Found 17 product links\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=E&Year=2015&page=6\n",
            "   ğŸ” Page 6 - Found 17 product links\n",
            "  âœ… Wrote 51 rows | Total scraped: 7294\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=E&Year=2015&page=7\n",
            "   ğŸ” Page 7 - Found 17 product links\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=E&Year=2015&page=8\n",
            "   ğŸ” Page 8 - Found 17 product links\n",
            "  ğŸ’¾ Checkpoint saved at Year 2015, Rating E, Page 8\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=E&Year=2015&page=9\n",
            "   ğŸ” Page 9 - Found 4 product links\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=E&Year=2015&page=10\n",
            "  âš ï¸ Failed to load product links: Message: \n",
            "\n",
            "   ğŸ” Page 10 - Found 0 product links\n",
            "  âœ… Wrote remaining 38 rows for Year 2015, Rating E\n",
            "ğŸŸ¢ Scraping DVDs for Year: 2015, Rating: tc\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=tc&Year=2015\n",
            "   ğŸ” Page 1 - Found 17 product links\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=tc&Year=2015&page=2\n",
            "   ğŸ” Page 2 - Found 4 product links\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=tc&Year=2015&page=3\n",
            "  âš ï¸ Failed to load product links: Message: \n",
            "\n",
            "   ğŸ” Page 3 - Found 0 product links\n",
            "  âœ… Wrote remaining 21 rows for Year 2015, Rating tc\n",
            "ğŸŸ¢ Scraping DVDs for Year: 2014, Rating: U\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=U&Year=2014\n",
            "   ğŸ” Page 1 - Found 17 product links\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=U&Year=2014&page=2\n",
            "   ğŸ” Page 2 - Found 17 product links\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=U&Year=2014&page=3\n",
            "   ğŸ” Page 3 - Found 17 product links\n",
            "  âœ… Wrote 51 rows | Total scraped: 7404\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=U&Year=2014&page=4\n",
            "   ğŸ” Page 4 - Found 17 product links\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=U&Year=2014&page=5\n",
            "   ğŸ” Page 5 - Found 17 product links\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=U&Year=2014&page=6\n",
            "   ğŸ” Page 6 - Found 17 product links\n",
            "  âœ… Wrote 51 rows | Total scraped: 7455\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=U&Year=2014&page=7\n",
            "   ğŸ” Page 7 - Found 17 product links\n",
            "  ğŸ’¾ Checkpoint saved at Year 2014, Rating U, Page 7\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=U&Year=2014&page=8\n",
            "   ğŸ” Page 8 - Found 17 product links\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=U&Year=2014&page=9\n",
            "   ğŸ” Page 9 - Found 17 product links\n",
            "  âœ… Wrote 51 rows | Total scraped: 7506\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=U&Year=2014&page=10\n",
            "   ğŸ” Page 10 - Found 7 product links\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=U&Year=2014&page=11\n",
            "  âš ï¸ Failed to load product links: Message: \n",
            "\n",
            "   ğŸ” Page 11 - Found 0 product links\n",
            "  âœ… Wrote remaining 7 rows for Year 2014, Rating U\n",
            "ğŸŸ¢ Scraping DVDs for Year: 2014, Rating: PG\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=PG&Year=2014\n",
            "   ğŸ” Page 1 - Found 17 product links\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=PG&Year=2014&page=2\n",
            "   ğŸ” Page 2 - Found 17 product links\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=PG&Year=2014&page=3\n",
            "   ğŸ” Page 3 - Found 17 product links\n",
            "  âœ… Wrote 51 rows | Total scraped: 7564\n",
            "     ğŸŒ Loading: https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)=PG&Year=2014&page=4\n",
            "   ğŸ” Page 4 - Found 17 product links\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Enhanced Webuy Complete DVD Listing Scraper with Resume and Checkpoint Functionality\n",
        "\n",
        "Features:\n",
        "- Checkpoint system with dual storage (Google Sheets + JSON)\n",
        "- Resume from last position\n",
        "- Append mode (never clears existing data)\n",
        "- Robust error handling and deduplication\n",
        "\"\"\"\n",
        "\n",
        "!pip install selenium gspread google-auth oauth2client --quiet\n",
        "\n",
        "import time\n",
        "import re\n",
        "import random\n",
        "import json\n",
        "import os\n",
        "import gspread\n",
        "from google.colab import auth\n",
        "from google.auth import default\n",
        "from urllib.parse import urlparse, parse_qs, quote\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from datetime import datetime\n",
        "\n",
        "# === CONFIGURATION ===\n",
        "SPREADSHEET_ID = \"1rRa8QKtkE0NmN3DVF2SeUJfMlvkW51YribIsTtscb68\"\n",
        "SHEET_NAME = \"DVD\"\n",
        "CHECKPOINT_SHEET = \"Checkpoints\"\n",
        "JSON_CHECKPOINT_FILE = \"/content/dvd_checkpoint.json\"\n",
        "AGE_RATINGS = [\"U\", \"PG\", \"12\", \"15\", \"18\", \"E\", \"tc\"]\n",
        "MAX_RETRIES = 2\n",
        "CHECKPOINT_FREQUENCY = 10  # Save checkpoint every 10 pages\n",
        "\n",
        "# === GOOGLE SHEETS SETUP ===\n",
        "auth.authenticate_user()\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)\n",
        "sheet = gc.open_by_key(SPREADSHEET_ID)\n",
        "\n",
        "# === CHECKPOINT FUNCTIONS ===\n",
        "def load_checkpoint_from_sheets():\n",
        "    \"\"\"Load checkpoint from Google Sheets\"\"\"\n",
        "    try:\n",
        "        checkpoint_ws = sheet.worksheet(CHECKPOINT_SHEET)\n",
        "        records = checkpoint_ws.get_all_records()\n",
        "        if records:\n",
        "            latest = records[-1]  # Get most recent checkpoint\n",
        "            return {\n",
        "                'year': int(latest['year']),\n",
        "                'rating': str(latest['rating']),  # Convert to string to match AGE_RATINGS\n",
        "                'page': int(latest['page']),\n",
        "                'scraped_count': int(latest['scraped_count']),\n",
        "                'timestamp': latest['timestamp']\n",
        "            }\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ Error loading checkpoint from sheets: {e}\")\n",
        "    return None\n",
        "\n",
        "def load_checkpoint_from_json():\n",
        "    \"\"\"Load checkpoint from JSON file\"\"\"\n",
        "    try:\n",
        "        if os.path.exists(JSON_CHECKPOINT_FILE):\n",
        "            with open(JSON_CHECKPOINT_FILE, 'r') as f:\n",
        "                data = json.load(f)\n",
        "                # Ensure rating is a string\n",
        "                data['rating'] = str(data['rating'])\n",
        "                return data\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ Error loading checkpoint from JSON: {e}\")\n",
        "    return None\n",
        "\n",
        "def save_checkpoint(year, rating, page, scraped_count):\n",
        "    \"\"\"Save checkpoint to both Google Sheets and JSON\"\"\"\n",
        "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    checkpoint_data = {\n",
        "        'year': year,\n",
        "        'rating': rating,\n",
        "        'page': page,\n",
        "        'scraped_count': scraped_count,\n",
        "        'timestamp': timestamp\n",
        "    }\n",
        "\n",
        "    # Save to JSON (local backup)\n",
        "    try:\n",
        "        with open(JSON_CHECKPOINT_FILE, 'w') as f:\n",
        "            json.dump(checkpoint_data, f)\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ Failed to save JSON checkpoint: {e}\")\n",
        "\n",
        "    # Save to Google Sheets\n",
        "    try:\n",
        "        try:\n",
        "            checkpoint_ws = sheet.worksheet(CHECKPOINT_SHEET)\n",
        "        except gspread.WorksheetNotFound:\n",
        "            # Create checkpoint sheet if it doesn't exist\n",
        "            checkpoint_ws = sheet.add_worksheet(title=CHECKPOINT_SHEET, rows=\"100\", cols=\"10\")\n",
        "            headers = [\"year\", \"rating\", \"page\", \"scraped_count\", \"timestamp\"]\n",
        "            checkpoint_ws.append_row(headers)\n",
        "\n",
        "        checkpoint_ws.append_row([year, rating, page, scraped_count, timestamp])\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ Failed to save Google Sheets checkpoint: {e}\")\n",
        "\n",
        "def get_resume_info():\n",
        "    \"\"\"Try to load checkpoint and get user input for resume\"\"\"\n",
        "    # Try Google Sheets first\n",
        "    checkpoint = load_checkpoint_from_sheets()\n",
        "    if not checkpoint:\n",
        "        # Fallback to JSON\n",
        "        checkpoint = load_checkpoint_from_json()\n",
        "\n",
        "    if checkpoint:\n",
        "        print(f\"\\nğŸ”„ Found checkpoint:\")\n",
        "        print(f\"   Year: {checkpoint['year']}\")\n",
        "        print(f\"   Rating: {checkpoint['rating']}\")\n",
        "        print(f\"   Last completed page: {checkpoint['page']}\")\n",
        "        print(f\"   Items scraped: {checkpoint['scraped_count']}\")\n",
        "        print(f\"   Timestamp: {checkpoint['timestamp']}\")\n",
        "\n",
        "        resume_choice = input(f\"\\nPress Enter to resume from here, or type 'new' for fresh start: \").strip()\n",
        "\n",
        "        if resume_choice.lower() != 'new':\n",
        "            # Resume from checkpoint\n",
        "            return {\n",
        "                'start_year': checkpoint['year'],\n",
        "                'end_year': checkpoint['year'],  # Will be updated below\n",
        "                'resume_rating': checkpoint['rating'],\n",
        "                'resume_page': checkpoint['page'] + 1,\n",
        "                'scraped_count': checkpoint['scraped_count']\n",
        "            }\n",
        "\n",
        "    # Fresh start or no checkpoint found\n",
        "    print(\"\\nğŸ†• Starting fresh scrape\")\n",
        "    start_year = int(input(\"ğŸ”¢ Enter the START year (e.g. 2025): \"))\n",
        "    end_year = int(input(\"ğŸ”» Enter the END year (e.g. 2010): \"))\n",
        "\n",
        "    return {\n",
        "        'start_year': start_year,\n",
        "        'end_year': end_year,\n",
        "        'resume_rating': None,\n",
        "        'resume_page': 1,\n",
        "        'scraped_count': 0\n",
        "    }\n",
        "\n",
        "# === INITIALIZE RESUME INFO ===\n",
        "resume_info = get_resume_info()\n",
        "start_year = resume_info['start_year']\n",
        "end_year = resume_info['end_year']\n",
        "\n",
        "# If resuming, ask for end year\n",
        "if resume_info['resume_rating']:\n",
        "    end_year = int(input(f\"ğŸ”» Enter the END year (currently resuming {start_year}): \"))\n",
        "\n",
        "YEARS = list(range(start_year, end_year - 1, -1))\n",
        "scraped_count = resume_info['scraped_count']\n",
        "\n",
        "# === SETUP WORKSHEETS ===\n",
        "# Main DVD worksheet - create if doesn't exist, but never clear\n",
        "try:\n",
        "    worksheet = sheet.worksheet(SHEET_NAME)\n",
        "    print(f\"ğŸ“‹ Using existing '{SHEET_NAME}' worksheet (appending data)\")\n",
        "except gspread.WorksheetNotFound:\n",
        "    worksheet = sheet.add_worksheet(title=SHEET_NAME, rows=\"1000\", cols=\"10\")\n",
        "    headers = [\"Title\", \"Product ID\", \"Category\", \"Super Category\", \"Price\", \"Image URL\"]\n",
        "    worksheet.append_row(headers)\n",
        "    print(f\"ğŸ“‹ Created new '{SHEET_NAME}' worksheet\")\n",
        "\n",
        "# === SELENIUM SETUP ===\n",
        "def create_driver():\n",
        "    options = Options()\n",
        "    options.add_argument(\"--headless\")\n",
        "    options.add_argument(\"--no-sandbox\")\n",
        "    options.add_argument(\"--disable-dev-shm-usage\")\n",
        "    options.add_argument(\"--disable-gpu\")\n",
        "    options.add_argument(\"--window-size=1920,1080\")\n",
        "    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
        "    options.add_argument(\"--user-agent=Mozilla/5.0\")\n",
        "    driver = webdriver.Chrome(options=options)\n",
        "    driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
        "    return driver\n",
        "\n",
        "# === FALLBACK IMAGE URL BUILDER ===\n",
        "def construct_image_url(product_id, category_name):\n",
        "    encoded_path = quote(category_name, safe='')\n",
        "    return f\"https://uk.static.webuy.com/product_images/DVD/{encoded_path}/{product_id}_l.jpg\"\n",
        "\n",
        "# === PRODUCT LINKS ===\n",
        "def get_product_links(driver):\n",
        "    try:\n",
        "        # Wait for either products to appear OR for 'no results' to show\n",
        "        WebDriverWait(driver, 30).until(\n",
        "            EC.any_of(\n",
        "                EC.presence_of_element_located((By.CSS_SELECTOR, \"a[href*='product-detail']\")),\n",
        "                EC.presence_of_element_located((By.CSS_SELECTOR, \".noResults, .notFound, .search-no-results\"))\n",
        "            )\n",
        "        )\n",
        "        time.sleep(2.5)\n",
        "\n",
        "        try:\n",
        "            elements = driver.find_elements(By.CSS_SELECTOR, \"a[href*='product-detail']\")\n",
        "            links = [e.get_attribute(\"href\") for e in elements if e.get_attribute(\"href\")]\n",
        "        except Exception:\n",
        "            time.sleep(1)\n",
        "            elements = driver.find_elements(By.CSS_SELECTOR, \"a[href*='product-detail']\")\n",
        "            links = [e.get_attribute(\"href\") for e in elements if e.get_attribute(\"href\")]\n",
        "\n",
        "        if not links:\n",
        "            print(\"  âš ï¸ No product links found. Dumping page source snippet for review:\")\n",
        "            print(driver.page_source[:1000])\n",
        "\n",
        "        return list(set(links))\n",
        "    except Exception as e:\n",
        "        print(f\"  âš ï¸ Failed to load product links: {e}\")\n",
        "        return []\n",
        "\n",
        "# === SCRAPER LOGIC ===\n",
        "def extract_product_id(url):\n",
        "    return parse_qs(urlparse(url).query).get(\"id\", [None])[0]\n",
        "\n",
        "def scrape_product_data(driver, url, retries=0):\n",
        "    try:\n",
        "        driver.get(url)\n",
        "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, \"main\")))\n",
        "        time.sleep(random.uniform(1.5, 3.0))\n",
        "\n",
        "        product_id = extract_product_id(url)\n",
        "        title = \"N/A\"\n",
        "        price = \"N/A\"\n",
        "\n",
        "        # Extract title\n",
        "        for sel in [\".product-title\", \"h1\", \".title\"]:\n",
        "            try:\n",
        "                elem = driver.find_element(By.CSS_SELECTOR, sel)\n",
        "                title = elem.text.strip()\n",
        "                if title:\n",
        "                    break\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "        # Extract price - FIXED REGEX PATTERN\n",
        "        for elem in driver.find_elements(By.XPATH, \"//*[contains(text(), 'Â£')]\"):\n",
        "            text = elem.text.strip()\n",
        "            match = re.search(r'Â£\\d+(\\.\\d{2})?', text)\n",
        "            if match:\n",
        "                price = match.group()\n",
        "                break\n",
        "\n",
        "        # Extract categories from URL\n",
        "        query = parse_qs(urlparse(url).query)\n",
        "        cat = query.get(\"categoryName\", [\"Unknown\"])[0]\n",
        "        supercat = query.get(\"superCatName\", [\"Unknown\"])[0]\n",
        "\n",
        "        # Extract image URL directly from product page\n",
        "        try:\n",
        "            image_element = driver.find_element(By.CSS_SELECTOR, \"img[src*='product_images']\")\n",
        "            image_url = image_element.get_attribute(\"src\")\n",
        "        except:\n",
        "            image_url = construct_image_url(product_id, cat)\n",
        "\n",
        "        return [title, product_id, cat, supercat, price, image_url]\n",
        "    except Exception as e:\n",
        "        if retries < MAX_RETRIES:\n",
        "            time.sleep(10)\n",
        "            return scrape_product_data(driver, url, retries + 1)\n",
        "        return None\n",
        "\n",
        "# === MAIN LOOP WITH RESUME LOGIC ===\n",
        "driver = create_driver()\n",
        "row_buffer = []\n",
        "seen_ids = set()  # For current session deduplication\n",
        "pages_processed = 0\n",
        "\n",
        "# Determine where to start based on resume logic\n",
        "start_rating_index = 0\n",
        "start_page = 1\n",
        "should_resume = False\n",
        "\n",
        "if resume_info['resume_rating']:\n",
        "    try:\n",
        "        # Find the rating in our AGE_RATINGS list\n",
        "        resume_rating = str(resume_info['resume_rating'])  # Ensure it's a string\n",
        "        start_rating_index = AGE_RATINGS.index(resume_rating)\n",
        "        start_page = resume_info['resume_page']\n",
        "        should_resume = True\n",
        "        print(f\"ğŸ”„ Successfully set resume point: Rating '{resume_rating}' (index {start_rating_index}), Page: {start_page}\")\n",
        "    except ValueError:\n",
        "        print(f\"âš ï¸ Rating '{resume_info['resume_rating']}' not found in AGE_RATINGS {AGE_RATINGS}\")\n",
        "        print(\"âš ï¸ Available ratings are:\", AGE_RATINGS)\n",
        "        print(\"âš ï¸ Starting fresh from beginning\")\n",
        "        should_resume = False\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ Error setting up resume: {e}\")\n",
        "        should_resume = False\n",
        "\n",
        "for year in YEARS:\n",
        "    # Skip years that are before our resume year\n",
        "    if should_resume and year > resume_info['start_year']:\n",
        "        continue\n",
        "\n",
        "    # If this is the resume year, start from the correct rating\n",
        "    rating_start_idx = start_rating_index if (should_resume and year == resume_info['start_year']) else 0\n",
        "\n",
        "    for rating_idx in range(rating_start_idx, len(AGE_RATINGS)):\n",
        "        rating = AGE_RATINGS[rating_idx]\n",
        "        print(f\"ğŸŸ¢ Scraping DVDs for Year: {year}, Rating: {rating}\")\n",
        "        base_url = f\"https://uk.webuy.com/search?stext=dvd&Age+Rating+(BBFC)={rating}&Year={year}\"\n",
        "\n",
        "        stop_pagination = False\n",
        "\n",
        "        # Determine starting page\n",
        "        if should_resume and year == resume_info['start_year'] and rating_idx == start_rating_index:\n",
        "            current_start_page = start_page\n",
        "            print(f\"   ğŸ“ Resuming from page {current_start_page}\")\n",
        "        else:\n",
        "            current_start_page = 1\n",
        "\n",
        "        for page in range(current_start_page, 61):\n",
        "            if stop_pagination:\n",
        "                break\n",
        "\n",
        "            # Handle page 1 separately (no page parameter)\n",
        "            if page == 1:\n",
        "                page_url = base_url\n",
        "            else:\n",
        "                page_url = base_url + f\"&page={page}\"\n",
        "\n",
        "            for attempt in range(2):\n",
        "                try:\n",
        "                    print(f\"     ğŸŒ Loading: {page_url}\")\n",
        "                    driver.get(page_url)\n",
        "                    time.sleep(random.uniform(1.5, 3.5))\n",
        "\n",
        "                    product_links = get_product_links(driver)\n",
        "                    print(f\"   ğŸ” Page {page} - Found {len(product_links)} product links\")\n",
        "\n",
        "                    if not product_links:\n",
        "                        stop_pagination = True\n",
        "                        break\n",
        "\n",
        "                    # Track new products found on this page\n",
        "                    new_products_found = 0\n",
        "\n",
        "                    # Process each product link\n",
        "                    for link in product_links:\n",
        "                        product_id = extract_product_id(link)\n",
        "\n",
        "                        # Skip if already scraped in this session\n",
        "                        if product_id in seen_ids:\n",
        "                            continue\n",
        "\n",
        "                        # This is a new product\n",
        "                        new_products_found += 1\n",
        "                        data = scrape_product_data(driver, link)\n",
        "                        if data:\n",
        "                            row_buffer.append(data)\n",
        "                            seen_ids.add(product_id)\n",
        "                            scraped_count += 1\n",
        "\n",
        "                    # If no new products found, stop pagination\n",
        "                    if new_products_found == 0:\n",
        "                        print(f\"  â¹ï¸  No new products on page {page} - stopping pagination for this year/rating\")\n",
        "                        stop_pagination = True\n",
        "                        break\n",
        "\n",
        "                    # Write to Google Sheets in batches\n",
        "                    if len(row_buffer) >= 50:\n",
        "                        worksheet.append_rows(row_buffer, value_input_option=\"USER_ENTERED\")\n",
        "                        print(f\"  âœ… Wrote {len(row_buffer)} rows | Total scraped: {scraped_count}\")\n",
        "                        row_buffer.clear()\n",
        "\n",
        "                    pages_processed += 1\n",
        "\n",
        "                    # Save checkpoint every CHECKPOINT_FREQUENCY pages\n",
        "                    if pages_processed % CHECKPOINT_FREQUENCY == 0:\n",
        "                        save_checkpoint(year, rating, page, scraped_count)\n",
        "                        print(f\"  ğŸ’¾ Checkpoint saved at Year {year}, Rating {rating}, Page {page}\")\n",
        "\n",
        "                    # Longer delay every 10 pages\n",
        "                    if page % 10 == 0:\n",
        "                        time.sleep(random.uniform(8, 15))\n",
        "\n",
        "                    break  # Successful, exit retry loop\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"  âš ï¸ Attempt {attempt+1} failed on page {page}: {e}\")\n",
        "                    time.sleep(10)\n",
        "\n",
        "        # Write remaining buffered data and save checkpoint for this year/rating\n",
        "        if row_buffer:\n",
        "            worksheet.append_rows(row_buffer, value_input_option=\"USER_ENTERED\")\n",
        "            print(f\"  âœ… Wrote remaining {len(row_buffer)} rows for Year {year}, Rating {rating}\")\n",
        "            row_buffer.clear()\n",
        "\n",
        "        # Save checkpoint after completing each year/rating combination\n",
        "        last_page = page if 'page' in locals() else current_start_page\n",
        "        save_checkpoint(year, rating, last_page, scraped_count)\n",
        "\n",
        "        # Reset resume flag after first use\n",
        "        if should_resume and year == resume_info['start_year'] and rating_idx == start_rating_index:\n",
        "            should_resume = False  # Only apply resume logic once\n",
        "\n",
        "    # Reset start_rating_index for subsequent years (always start from beginning)\n",
        "    start_rating_index = 0\n",
        "\n",
        "# Clean up\n",
        "driver.quit()\n",
        "\n",
        "# Final checkpoint and summary\n",
        "if YEARS and AGE_RATINGS:\n",
        "    save_checkpoint(YEARS[-1], AGE_RATINGS[-1], 60, scraped_count)\n",
        "\n",
        "print(f\"\\nğŸ‰ SCRAPING COMPLETED!\")\n",
        "print(f\"ğŸ“Š Total items scraped in this session: {scraped_count}\")\n",
        "print(f\"ğŸ“„ Data saved to Google Sheets tab '{SHEET_NAME}'\")\n",
        "print(f\"ğŸ’¾ Final checkpoint saved to both Google Sheets and JSON\")\n",
        "\n",
        "# Clean up checkpoint file\n",
        "try:\n",
        "    if os.path.exists(JSON_CHECKPOINT_FILE):\n",
        "        os.remove(JSON_CHECKPOINT_FILE)\n",
        "        print(\"ğŸ§¹ Cleaned up local checkpoint file\")\n",
        "except:\n",
        "    pass"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPzV4M6OdWK6iMn5+h75fZb",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}