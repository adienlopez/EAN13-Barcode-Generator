{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOtP8x8k11rmK8JsY1YdB1X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adienlopez/EAN13-Barcode-Generator/blob/main/Webuy_Complete_DVD_Listing_Scraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Final Webuy DVD scraper with direct image scraping (real folder names)\n",
        "\n",
        "!pip install selenium gspread google-auth oauth2client --quiet\n",
        "\n",
        "import time\n",
        "import re\n",
        "import random\n",
        "import gspread\n",
        "from google.colab import auth\n",
        "from google.auth import default\n",
        "from urllib.parse import urlparse, parse_qs, quote\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "\n",
        "# === CONFIGURATION ===\n",
        "SPREADSHEET_ID = \"1rRa8QKtkE0NmN3DVF2SeUJfMlvkW51YribIsTtscb68\"\n",
        "SHEET_NAME = \"Sheet1\"\n",
        "start_year = int(input(\"üî¢ Enter the start year (e.g. 2005): \"))\n",
        "YEARS = list(range(start_year, 2026))\n",
        "AGE_RATINGS = [\"U\", \"PG\", \"12\", \"15\", \"18\", \"E\", \"tc\"]\n",
        "MAX_RETRIES = 2\n",
        "\n",
        "# === GOOGLE SHEETS SETUP ===\n",
        "auth.authenticate_user()\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)\n",
        "sheet = gc.open_by_key(SPREADSHEET_ID).worksheet(SHEET_NAME)\n",
        "headers = [\"Title\", \"Product ID\", \"Category\", \"Super Category\", \"Price\", \"Image URL\"]\n",
        "sheet.clear()\n",
        "sheet.append_row(headers)\n",
        "\n",
        "# === SELENIUM SETUP ===\n",
        "def create_driver():\n",
        "    options = Options()\n",
        "    options.add_argument(\"--headless\")\n",
        "    options.add_argument(\"--no-sandbox\")\n",
        "    options.add_argument(\"--disable-dev-shm-usage\")\n",
        "    options.add_argument(\"--disable-gpu\")\n",
        "    options.add_argument(\"--window-size=1920,1080\")\n",
        "    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
        "    options.add_argument(\"--user-agent=Mozilla/5.0\")\n",
        "    driver = webdriver.Chrome(options=options)\n",
        "    driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
        "    return driver\n",
        "\n",
        "# === FALLBACK URL BUILDER ===\n",
        "def construct_image_url(product_id, category_name):\n",
        "    encoded_path = quote(category_name, safe='')\n",
        "    return f\"https://uk.static.webuy.com/product_images/DVD/{encoded_path}/{product_id}_l.jpg\"\n",
        "\n",
        "# === PRODUCT LINKS ===\n",
        "def get_product_links(driver):\n",
        "    try:\n",
        "        WebDriverWait(driver, 15).until(\n",
        "            EC.presence_of_element_located((By.CSS_SELECTOR, \"a[href*='product-detail']\"))\n",
        "        )\n",
        "        elements = driver.find_elements(By.CSS_SELECTOR, \"a[href*='product-detail']\")\n",
        "        return list({e.get_attribute(\"href\") for e in elements if e.get_attribute(\"href\")})\n",
        "    except:\n",
        "        return []\n",
        "\n",
        "# === SCRAPER LOGIC ===\n",
        "def extract_product_id(url):\n",
        "    return parse_qs(urlparse(url).query).get(\"id\", [None])[0]\n",
        "\n",
        "def scrape_product_data(driver, url, retries=0):\n",
        "    try:\n",
        "        driver.get(url)\n",
        "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, \"main\")))\n",
        "        time.sleep(random.uniform(1.5, 3.0))\n",
        "\n",
        "        product_id = extract_product_id(url)\n",
        "        title = \"N/A\"\n",
        "        price = \"N/A\"\n",
        "\n",
        "        for sel in [\".product-title\", \"h1\", \".title\"]:\n",
        "            try:\n",
        "                elem = driver.find_element(By.CSS_SELECTOR, sel)\n",
        "                title = elem.text.strip()\n",
        "                if title:\n",
        "                    break\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "        for elem in driver.find_elements(By.XPATH, \"//*[contains(text(), '¬£')]\"):\n",
        "            text = elem.text.strip()\n",
        "            match = re.search(r'¬£\\\\d+(\\\\.\\\\d{2})?', text)\n",
        "            if match:\n",
        "                price = match.group()\n",
        "                break\n",
        "\n",
        "        query = parse_qs(urlparse(url).query)\n",
        "        cat = query.get(\"categoryName\", [\"Unknown\"])[0]\n",
        "        supercat = query.get(\"superCatName\", [\"Unknown\"])[0]\n",
        "\n",
        "        # ‚úÖ NEW: Extract image URL directly from product page\n",
        "        try:\n",
        "            image_element = driver.find_element(By.CSS_SELECTOR, \"img[src*='product_images']\")\n",
        "            image_url = image_element.get_attribute(\"src\")\n",
        "        except:\n",
        "            image_url = construct_image_url(product_id, cat)\n",
        "\n",
        "        return [title, product_id, cat, supercat, price, image_url]\n",
        "    except Exception as e:\n",
        "        if retries < MAX_RETRIES:\n",
        "            time.sleep(10)\n",
        "            return scrape_product_data(driver, url, retries + 1)\n",
        "        return None\n",
        "\n",
        "# === MAIN LOOP ===\n",
        "driver = create_driver()\n",
        "row_buffer = []\n",
        "scraped_count = 0\n",
        "\n",
        "for year in YEARS:\n",
        "    for rating in AGE_RATINGS:\n",
        "        print(f\"üü¢ Scraping DVDs for Year: {year}, Rating: {rating}\")\n",
        "        base_url = f\"https://uk.webuy.com/search?stext=dvd&Year={year}&Age+Rating+(BBFC)={rating}\"\n",
        "        for page in range(1, 61):\n",
        "            page_url = base_url + f\"&page={page}\"\n",
        "            try:\n",
        "                driver.get(page_url)\n",
        "                time.sleep(random.uniform(1.5, 3.5))\n",
        "                product_links = get_product_links(driver)\n",
        "                print(f\"   üîç Page {page} - Found {len(product_links)} product links\")\n",
        "                if not product_links:\n",
        "                    break\n",
        "                for link in product_links:\n",
        "                    data = scrape_product_data(driver, link)\n",
        "                    if data:\n",
        "                        row_buffer.append(data)\n",
        "                        scraped_count += 1\n",
        "                if len(row_buffer) >= 50:\n",
        "                    sheet.append_rows(row_buffer, value_input_option=\"USER_ENTERED\")\n",
        "                    print(f\"  ‚úÖ Wrote {len(row_buffer)} rows | Total scraped: {scraped_count}\")\n",
        "                    row_buffer.clear()\n",
        "                if page % 10 == 0:\n",
        "                    time.sleep(random.uniform(8, 15))\n",
        "            except Exception as e:\n",
        "                print(f\"  ‚ö†Ô∏è Error on page {page}: {e}\")\n",
        "                time.sleep(30)\n",
        "\n",
        "        if row_buffer:\n",
        "            sheet.append_rows(row_buffer, value_input_option=\"USER_ENTERED\")\n",
        "            print(f\"  ‚úÖ Wrote remaining {len(row_buffer)} rows for Year {year}, Rating {rating}\")\n",
        "            row_buffer.clear()\n",
        "\n",
        "driver.quit()\n",
        "print(f\"üéâ DONE: {scraped_count} DVD items scraped and saved to Google Sheets.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGN7PN15Mcfz",
        "outputId": "129c6ed1-d0aa-4176-8b0b-c3a0693c294c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üî¢ Enter the start year (e.g. 2005): 2024\n",
            "üü¢ Scraping DVDs for Year: 2024, Rating: U\n",
            "   üîç Page 1 - Found 14 product links\n"
          ]
        }
      ]
    }
  ]
}